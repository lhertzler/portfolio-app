<h2>Introduction</h2>
<p>
  For as long as I’ve been building for the web, I’ve wanted one specific thing: a music player that
  keeps playing while you move around the site. No awkward restarts, no janky reloads — just a
  smooth, app-like audio experience inside a browser. For years that goal fought against the
  limits of older stacks. Then React and Next.js came along, and suddenly the thing that felt
  nearly impossible became a clean, reliable pattern.
</p>
<p>
  In this article, I’ll walk you through how I build <strong>persistent music players in React &amp; Next.js</strong>:
  the architecture, the tradeoffs, and the real-world lessons from pushing this pattern way
  beyond a simple “play/pause” component. I’ll reference the exact approach I used on my own
  portfolio — a global Zustand store, a shared layout that never unmounts, and a canvas-based
  waveform visualiser tied to the audio frequencies. If you’re an entrepreneur, tech lead, or dev
  planning a custom app with rich media, this is how I make it feel native, reliable, and fun.
</p>

<hr />

<h2>Background: The WordPress &amp; AJAX Era (A.K.A. The Pain)</h2>

<h3>Trying to Force a Persistent Player into WordPress</h3>
<p>
  Long before React took over, I tried to build the first version of SoundVent on WordPress.
  I wanted exactly what my current portfolio has now: hit play, browse around, keep listening.
  In that ecosystem, the only mildly feasible approach was to go all-in on <strong>AJAX navigation</strong>.
  Instead of letting the browser do a full page load, you intercept links, fetch new content
  over AJAX, and manually swap parts of the DOM while trying to keep the audio element alive.
</p>
<p>
  On very small sites, it kind of worked. But as soon as I tried to scale it to something more
  ambitious — a full social network with feeds, profiles, messaging, notifications — the whole
  thing became fragile. Plugins assumed full reloads. Themes assumed page-level scripts.
  Caching and SEO collided with AJAX hacks. It was like bolting a spaceship engine onto a
  family sedan.
</p>

<h3>The Core Problem: Fighting the Platform Instead of Working With It</h3>
<p>
  To keep audio persistent in that environment, I had to:
</p>
<ul>
  <li>Intercept every navigation instead of using normal links.</li>
  <li>Issue AJAX requests for every page change.</li>
  <li>Parse the HTML response and surgically replace only specific DOM nodes.</li>
  <li>Re-bind scripts in exactly the right order so plugins wouldn’t break.</li>
  <li>Hope updates didn’t quietly blow everything up.</li>
</ul>
<p>
  It was brittle by design. WordPress was built around full page loads and PHP templates, not a
  single long-lived UI tree. I spent more time babysitting the illusion than building the actual
  product experience.
</p>

<h3>Why Next.js Changed Everything</h3>
<p>
  React and Next.js flipped the entire architecture. Instead of hacking around full reloads, I
  could treat the app as <strong>one persistent React tree</strong> where navigation simply swaps out
  children. The audio player lives at the layout level — above the individual pages — so it
  never unmounts when the route changes. No DOM surgery. No plugin roulette. Just a
  stable parent component and client-side routing optimized for this use case.
</p>
<p>
  For the first time, a persistent player felt natural, not hacked on. That’s the mindset I use now
  for my portfolio, SoundVent, and any custom app that needs continuous audio.
</p>

<hr />

<h2>What a “Persistent Music Player” Really Is</h2>
<p>
  When I say “persistent music player,” I don’t just mean a play/pause button glued to the
  bottom of the page. In practice, it needs to:
</p>
<ul>
  <li>Keep playing while users navigate between different routes.</li>
  <li>Remember the current track, position, and queue.</li>
  <li>Accept commands from anywhere in the app (play this track, skip, seek, etc.).</li>
  <li>Feel native: no awkward resets or flicker when the route changes.</li>
  <li>Optionally drive visualisations, theming, and UI states across the app.</li>
</ul>
<p>
  In other words, a persistent player is a combination of:
</p>
<ul>
  <li><strong>Global audio state</strong> (stored centrally, not per-page).</li>
  <li><strong>A shared layout</strong> that keeps the player mounted.</li>
  <li><strong>A real audio implementation</strong> (via <code>HTMLAudioElement</code> and/or Web Audio API).</li>
  <li><strong>Integration points</strong> from other components to control it.</li>
</ul>
<p>
  Once you see it as shared state + shared UI + stable layout, the architecture becomes
  straightforward to design.
</p>

<hr />

<h2>The Core Stack: React, Next.js, Zustand &amp; Canvas</h2>

<h3>React for Components, Next.js for Routing</h3>
<p>
  React gives me the component model: small, reusable pieces of UI with props and state.
  Next.js gives me structure: file-based routing, layouts, server rendering, and app-wide
  composition. Together, they let me treat the browser like a single application instead of
  disconnected pages.
</p>

<h3>Zustand for Global Audio State</h3>
<p>
  For the player on my portfolio, I use a dedicated Zustand store called
  <code>usePlayerStore</code>. This store knows:
</p>
<ul>
  <li>The current queue of tracks.</li>
  <li>The currently active track id.</li>
  <li>Whether playback is active or paused.</li>
  <li>The current playback position in seconds.</li>
  <li>Helper actions like <code>playTrack</code>, <code>pause</code>, <code>resume</code>, <code>next</code>, <code>prev</code>, and <code>seek</code>.</li>
</ul>
<p>
  Inside the player component, I destructure exactly what I need:
</p>
<pre><code>const {
  queue,
  currentTrackId,
  isPlaying,
  positionSeconds,
  setQueue,
  playTrack,
  pause,
  resume,
  next,
  prev,
  seek,
} = usePlayerStore();
</code></pre>
<p>
  This store is the “brain” of the audio system. It doesn’t play sound itself — it just describes
  what should be happening. The player component is responsible for making the browser’s
  audio APIs line up with that state.
</p>

<h3>Canvas for the Waveform Visualiser</h3>
<p>
  On top of standard playback, I use a separate component,
  <code>&lt;WaveformVisualizer /&gt;</code>, that takes the current <code>HTMLAudioElement</code> and an <code>isPlaying</code> flag.
  Inside, it sets up an <code>AudioContext</code> and <code>AnalyserNode</code>, then draws a bar-style waveform to
  a canvas on every animation frame. That visual feedback is subtle, but it turns a basic player
  into something that feels intentionally designed.
</p>

<hr />

<h2>Where the Player Lives: Next.js Layouts That Never Unmount</h2>
<p>
  The secret to persistence isn’t a trick inside the player — it’s where the player is mounted
  in the tree.
</p>
<p>
  In my portfolio, the <code>&lt;AudioPlayer /&gt;</code> is rendered inside a shared layout under the App
  Router. That layout wraps all the “app” routes, so when you navigate between pages, the
  layout (and therefore the player) stays mounted the whole time.
</p>
<p>
  A simplified version of the structure looks like:
</p>
<pre><code>app/
  layout.tsx          // Global shell (theme, base styles)
  (site)/             // Route group for the main site
    layout.tsx        // Site layout (includes AudioPlayer)
    page.tsx          // Home
    blog/
      page.tsx        // Blog index
    portfolio/
      page.tsx        // Portfolio index
    ...
</code></pre>
<p>
  And the layout that holds the player might look like this:
</p>
<pre><code>// app/(site)/layout.tsx
import { AudioPlayer } from '@/components/audio-player';

export default function SiteLayout({ children }: { children: React.ReactNode }) {
  return (
    &lt;div className="app-shell"&gt;
      &lt;header&gt;...site header...&lt;/header&gt;
      &lt;main&gt;{children}&lt;/main&gt;
      &lt;AudioPlayer /&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<p>
  Every page under <code>(site)</code> can interact with the audio store. The player, however, is never
  torn down when the route changes — which means the music keeps playing.
</p>

<hr />

<h2>Inside the Audio Player Component</h2>

<h3>Ref to the Audio Element</h3>
<p>
  In the player component, I create a ref to the underlying <code>&lt;audio&gt;</code> element:
</p>
<pre><code>const audioRef = useRef&lt;HTMLAudioElement | null&gt;(null);
</code></pre>
<p>
  That ref bridges the React world and the browser audio world. The audio element:
</p>
<ul>
  <li>Receives <code>src</code> updates when the current track changes.</li>
  <li>Listens to events like <code>timeupdate</code>, <code>loadedmetadata</code>, <code>ended</code>.</li>
  <li>Feeds progress and duration back into the Zustand store.</li>
</ul>

<h3>Syncing Store State &amp; Audio State</h3>
<p>
  There are two main loops:
</p>
<ol>
  <li>
    <strong>Store → Audio</strong>: when <code>isPlaying</code> changes, the effect decides whether to
    <code>audio.play()</code> or <code>audio.pause()</code>.
  </li>
  <li>
    <strong>Audio → Store</strong>: as the track plays, a <code>requestAnimationFrame</code> loop reads
    <code>audio.currentTime</code> and pushes it into <code>positionSeconds</code> in the store.
  </li>
</ol>
<p>
  That pattern keeps things predictable: the store describes intent, and the player makes sure
  the audio element matches it.
</p>

<hr />

<h2>Letting Any Page Control the Player</h2>
<p>
  One of the big wins of the global store approach is that any component can control the
  player without prop-drilling. For example, a track card in a list can do:
</p>
<pre><code>const { playTrack, setQueue } = usePlayerStore();

const handlePlayClick = () =&gt; {
  setQueue(tracks); // maybe the full playlist
  playTrack(track.id);
};
</code></pre>
<p>
  That’s exactly how my portfolio works: track data lives in a shared <code>tracks</code> module, and
  UI components simply call the store when they want something to play. The player listens
  and responds.
</p>

<hr />

<h2>Waveform Visualiser: Turning Audio into Motion</h2>
<p>
  The waveform visualiser lives in its own component:
</p>
<pre><code>interface WaveformVisualizerProps {
  audioElement: HTMLAudioElement | null;
  isPlaying: boolean;
  className?: string;
}

export function WaveformVisualizer({
  audioElement,
  isPlaying,
  className = '',
}: WaveformVisualizerProps) {
  // ...
}
</code></pre>
<p>
  Inside, it:
</p>
<ul>
  <li>Creates or reuses an <code>AudioContext</code>.</li>
  <li>Uses <code>createMediaElementSource(audioElement)</code> to connect the audio element.</li>
  <li>Attaches an <code>AnalyserNode</code> to read frequency data.</li>
  <li>Draws a series of bars to a <code>&lt;canvas&gt;</code> on every animation frame while audio is playing.</li>
</ul>
<p>
  It’s intentionally defensive: if a source already exists, it reconnects; if something goes wrong,
  it logs a warning instead of breaking the app. The result is a visual layer that feels smooth
  and synchronised with the music but doesn’t interfere with the core playback logic.
</p>

<hr />

<h2>Real UX Touches: Minimised State, Playlist Sheet &amp; Motion</h2>
<p>
  On top of the core tech, I layer in UX elements to make the player feel considered:
</p>
<ul>
  <li>A minimised state that tucks the player into a compact bar when you want it out of the way.</li>
  <li>A playlist sheet/modal that shows all available tracks using a <code>&lt;Sheet&gt;</code> component.</li>
  <li>Framer Motion animations for smooth enter/exit/transitions.</li>
  <li>Theme-aware styling so the player feels native to the rest of the site.</li>
</ul>
<p>
  These are built on top of the same foundation: Zustand for state, a persistent layout,
  and a single <code>&lt;AudioPlayer /&gt;</code> tied to an <code>HTMLAudioElement</code>. The details vary per project,
  but the underlying pattern is stable.
</p>

<hr />

<h2>Common Pitfalls &amp; How I Avoid Them</h2>

<h3>Strict Mode Double Mounts</h3>
<p>
  In development, React Strict Mode can cause effects to run twice, which can lead to
  duplicate <code>AudioContext</code> instances or repeated setup. I keep audio side effects inside
  guarded hooks, clean up thoroughly on unmount, and avoid doing heavy setup work directly
  in render.
</p>

<h3>Hydration &amp; Client-Only APIs</h3>
<p>
  Anything that touches <code>window</code>, <code>document</code>, <code>AudioContext</code>, or canvas needs to run on
  the client. The player and visualiser are declared as <code>'use client'</code> components, and all
  browser API code lives inside <code>useEffect</code> hooks to avoid hydration mismatches.
</p>

<h3>Overloading the Store</h3>
<p>
  It’s tempting to dump every bit of UI state into the audio store. I keep it focused on audio
  (queue, track, position, playback). UI concerns like “is the playlist sheet open?” or “is the
  player minimised?” live in component-level state or dedicated UI stores. This keeps things
  easier to reason about.
</p>

<hr />

<h2>Quick Takeaways</h2>
<ul>
  <li>A persistent music player is really about <strong>shared layout + global state</strong>, not DOM tricks.</li>
  <li>Next.js App Router layouts make it natural to keep a player mounted across routes.</li>
  <li>Zustand (or similar) gives you a clean, global audio store that any component can use.</li>
  <li>Web Audio + canvas transforms a plain player into a branded, expressive experience.</li>
  <li>Careful handling of Strict Mode, hydration, and state boundaries keeps the system stable.</li>
  <li>This pattern scales from “simple portfolio flex” to “full media platform” without re-architecture.</li>
</ul>

<hr />

<h2>Visual &amp; Diagram Ideas</h2>
<p>Here are a few visuals that would complement this article well:</p>
<ol>
  <li>
    <strong>Architecture Diagram: “One Tree, One Player”</strong><br />
    Boxes showing:
    <ul>
      <li>Top-level <code>SiteLayout</code> with <code>AudioPlayer</code> and <code>AudioProvider</code>/<code>usePlayerStore</code>.</li>
      <li>Nested pages (<code>Home</code>, <code>Blog</code>, <code>Portfolio</code>) swapping under the layout.</li>
      <li>Arrows from pages calling <code>playTrack()</code> into the audio store.</li>
    </ul>
    <em>Alt text:</em> “Diagram of a persistent React and Next.js music player architecture with shared layout and global store.”
  </li>
  <li>
    <strong>State Flow Diagram</strong><br />
    A simple flow:
    <ul>
      <li>User clicks a track &rarr; component calls <code>playTrack()</code>.</li>
      <li><code>usePlayerStore</code> updates <code>currentTrackId</code> and <code>isPlaying</code>.</li>
      <li><code>AudioPlayer</code> updates the <code>&lt;audio&gt;</code> element and starts playback.</li>
      <li>Audio events update <code>positionSeconds</code> back into the store.</li>
    </ul>
    <em>Alt text:</em> “State flow for a global audio store and player in React and Next.js.”
  </li>
  <li>
    <strong>Layout Structure Visual</strong><br />
    A diagram of the <code>app/(site)/layout.tsx</code> tree, highlighting the persistent player region
    and children routes.
    <em>Alt text:</em> “Next.js App Router layout structure showing a persistent music player component.”
  </li>
  <li>
    <strong>Waveform Visualiser Screenshot</strong><br />
    A mock or screenshot of the actual player from your portfolio, showing the waveform bars
    moving as music plays.
    <em>Alt text:</em> “Custom React and Next.js music player with canvas waveform visualiser.”
  </li>
  <li>
    <strong>Before/After UX Comparison</strong><br />
    Side-by-side:
    <ul>
      <li>Left: traditional site where audio restarts on every page load.</li>
      <li>Right: persistent Next.js app where music continues across navigation.</li>
    </ul>
    <em>Alt text:</em> “Comparison between traditional page reload audio and persistent app-wide music player in Next.js.”
  </li>
</ol>

<hr />

<h2>Conclusion</h2>
<p>
  Building a persistent music player used to feel like wrestling the platform. In the WordPress +
  AJAX era, I spent a lot of time trying to keep one fragile audio element alive while everything
  else reloaded around it. It was clever in theory, but it never felt stable enough for large,
  complex systems like a full social network.
</p>
<p>
  With React and Next.js, especially the App Router and shared layouts, the entire problem
  looks different. Instead of fighting page reloads, I design a single React tree with a stable
  layout and a global audio store. The player on my portfolio — with its persistent playback,
  playlist sheet, waveform visualiser, and smooth navigation — is a direct result of that
  architecture.
</p>
<p>
  For entrepreneurs, product teams, and anyone thinking about custom apps, this pattern
  means you can deliver <strong>app-like audio experiences</strong> in the browser without sacrificing
  maintainability or performance. And for me as a builder, it’s satisfying to know that the
  player I always wanted years ago is not only possible now — it’s something I can design,
  reason about, and extend with confidence.
</p>
<p>
  If you’re considering a product that needs continuous audio — a music platform, learning
  environment, content hub, or just a portfolio that quietly flexes your capabilities — React
  and Next.js give you the right foundation. And if you’d rather not stitch that architecture
  together alone, I’m always open to talking about what we could build together.
</p>

<hr />

<h2>FAQs</h2>

<h3>Do I need Next.js for a persistent music player, or is React enough?</h3>
<p>
  You can technically build a persistent player with plain React and a client-side router, as long
  as the player lives near the top of your component tree. Next.js just makes the overall app
  architecture cleaner: file-based routing, shared layouts, server rendering, and a solid pattern
  for keeping global UI elements (like a player) mounted across navigation.
</p>

<h3>Why did you choose Zustand instead of Redux or Context?</h3>
<p>
  For this specific use case, I wanted something lightweight, ergonomic, and easy to scale
  without a lot of boilerplate. Zustand hits that sweet spot: the API is simple, the store can be
  colocated with related logic, and components can subscribe to just what they need. React
  Context can work for smaller setups, but as the audio state grows (queue, progress, controls),
  Zustand helps keep things maintainable.
</p>

<h3>Can I reuse your pattern without the waveform visualiser?</h3>
<p>
  Absolutely. The waveform visualiser is completely optional. The core architecture — a
  persistent layout, a global player store, and a single audio component wired to that store —
  works perfectly well on its own. You can always add visualisation later if it fits your brand or
  product goals.
</p>

<h3>Does this kind of player hurt performance?</h3>
<p>
  A well-designed persistent player should have minimal impact on performance. It’s just one
  more component in the tree. The bigger performance wins (or losses) come from how you
  handle data fetching, rendering strategies, image optimisation, and bundle size. Using
  Next.js’s features and being thoughtful about your architecture will keep your app fast even
  with continuous audio.
</p>

<h3>What if I want a similar experience in my product?</h3>
<p>
  If you’re thinking about a music platform, content site, or product that needs continuous
  audio, the pattern I’ve described here can be adapted to your requirements — different
  track sources, custom UI, access control, analytics, and more. The important part is the
  architecture: keeping the player persistent, the state predictable, and the app structure
  clean. From there, we can layer on whatever experience your audience needs.
</p>

<hr />

<h2>Let's chat!</h2>
<p>
  Thanks for diving into this breakdown of how I build persistent music players in React &amp;
  Next.js. I’d love to hear your thoughts: <strong>if you could add a continuous audio experience to
  any project you’re working on right now, what would it be?</strong> Share your ideas, send this
  to someone who’s dreaming up a custom app, or reach out if you’d like to explore building
  something like this together.
</p>